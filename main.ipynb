{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Device Count: 1\n",
      "Current Device: 0\n",
      "Device Name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Cell 0: GPU Verification\n",
    "import torch\n",
    "\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Device Count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current Device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU detected - using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Core Setup\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import (\n",
    "    Wav2Vec2Processor,\n",
    "    Wav2Vec2ForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Global Settings\n",
    "class Config:\n",
    "    # Data settings\n",
    "    expected_labels = ['angry', 'fear', 'happy', 'neutral', 'sad']\n",
    "    audio_max_duration = 3  # seconds\n",
    "    sample_rate = 16000\n",
    "    \n",
    "    # Model settings\n",
    "    model_name = \"facebook/wav2vec2-base\"\n",
    "    batch_size = 4\n",
    "    learning_rate = 3e-5\n",
    "    num_epochs = 30\n",
    "    \n",
    "    # Path handling\n",
    "    base_path = Path(\"dataset\")\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:\n",
      "label\n",
      "happy      134\n",
      "neutral    134\n",
      "sad        133\n",
      "angry      127\n",
      "fear        70\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test dataset:\n",
      "label\n",
      "neutral    42\n",
      "happy      42\n",
      "sad        42\n",
      "angry      40\n",
      "fear       22\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Data Loading & Cleaning\n",
    "def load_and_validate_dataset(csv_path):\n",
    "    \"\"\"Load dataset with comprehensive validation\"\"\"\n",
    "    try:\n",
    "        # Detect header presence\n",
    "        with open(csv_path, 'r') as f:\n",
    "            first_line = f.readline().strip().lower()\n",
    "            has_header = any(label in first_line for label in ['path', 'audio', 'label', 'emotion'])\n",
    "        \n",
    "        df = pd.read_csv(\n",
    "            csv_path,\n",
    "            header=0 if has_header else None,\n",
    "            names=[\"audio_path\", \"label\"]\n",
    "        )\n",
    "        \n",
    "        # Clean paths\n",
    "        df[\"audio_path\"] = df[\"audio_path\"].apply(\n",
    "            lambda x: str(Path(x.replace(\"\\\\\", os.sep).replace(\"/\", os.sep)))\n",
    "        )\n",
    "        \n",
    "        # Clean labels\n",
    "        df[\"label\"] = df[\"label\"].str.strip().str.lower()\n",
    "        df[\"label\"] = df[\"label\"].replace({'emotion': 'neutral'})  # Fix observed error\n",
    "        \n",
    "        # Validate labels\n",
    "        invalid_labels = set(df[\"label\"]) - set(config.expected_labels)\n",
    "        if invalid_labels:\n",
    "            raise ValueError(f\"Invalid labels found: {invalid_labels}\")\n",
    "            \n",
    "        # Check file existence\n",
    "        missing_files = [p for p in df[\"audio_path\"] if not Path(p).exists()]\n",
    "        if missing_files:\n",
    "            raise FileNotFoundError(f\"Missing {len(missing_files)} audio files\")\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {csv_path}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Load datasets\n",
    "try:\n",
    "    train_df = load_and_validate_dataset(\"train_dataset.csv\")\n",
    "    test_df = load_and_validate_dataset(\"test_dataset.csv\")\n",
    "    \n",
    "    print(\"Train dataset:\")\n",
    "    print(train_df[\"label\"].value_counts())\n",
    "    print(\"\\nTest dataset:\")\n",
    "    print(test_df[\"label\"].value_counts())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Failed to load datasets:\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Dataset Pipeline\n",
    "class TamilEmotionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, processor):\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.max_length = config.audio_max_duration * config.sample_rate\n",
    "        \n",
    "        # Create label map\n",
    "        self.label_map = {label: idx for idx, label in enumerate(config.expected_labels)}\n",
    "        self.inverse_map = {v: k for k, v in self.label_map.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            # Load metadata\n",
    "            audio_path = self.df.iloc[idx][\"audio_path\"]\n",
    "            label = self.df.iloc[idx][\"label\"]\n",
    "            \n",
    "            # Validate label\n",
    "            if label not in self.label_map:\n",
    "                raise ValueError(f\"Invalid label {label}\")\n",
    "                \n",
    "            # Load audio\n",
    "            waveform, sr = librosa.load(\n",
    "                audio_path,\n",
    "                sr=config.sample_rate,\n",
    "                mono=True,\n",
    "                duration=config.audio_max_duration\n",
    "            )\n",
    "            \n",
    "            # Validate audio\n",
    "            if len(waveform) < 0.5 * sr:  # Minimum 0.5s\n",
    "                raise ValueError(\"Audio too short\")\n",
    "                \n",
    "            # Process features\n",
    "            inputs = self.processor(\n",
    "                waveform,\n",
    "                sampling_rate=sr,\n",
    "                padding=\"max_length\",\n",
    "                max_length=self.max_length,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"input_values\": inputs[\"input_values\"].squeeze(),\n",
    "                \"labels\": torch.tensor(self.label_map[label], dtype=torch.long)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {audio_path}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Handle invalid samples\"\"\"\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    return {\n",
    "        \"input_values\": torch.stack([b[\"input_values\"] for b in batch]),\n",
    "        \"labels\": torch.stack([b[\"labels\"] for b in batch])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\SER v.03\\venv\\Lib\\site-packages\\transformers\\configuration_utils.py:312: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 (Revised): Model Setup with Explicit GPU Handling\n",
    "try:\n",
    "    # Initialize processor\n",
    "    processor = Wav2Vec2Processor.from_pretrained(config.model_name)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TamilEmotionDataset(train_df, processor)\n",
    "    test_dataset = TamilEmotionDataset(test_df, processor)\n",
    "    \n",
    "    # Model config\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\nUsing device: {device}\")\n",
    "    \n",
    "    model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "        config.model_name,\n",
    "        num_labels=len(config.expected_labels)\n",
    "    ).to(device)  # Explicit device placement\n",
    "    \n",
    "    print(\"\\nModel device:\", next(model.parameters()).device)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Model initialization failed:\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\GitHub\\SER v.03\\venv\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Training Setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ser_results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=config.learning_rate,\n",
    "    per_device_train_batch_size=config.batch_size,\n",
    "    per_device_eval_batch_size=config.batch_size,\n",
    "    num_train_epochs=config.num_epochs,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    fp16=torch.cuda.is_available(),  # Enable mixed precision if GPU available\n",
    "    report_to=\"none\",  # Disable external logging\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\")\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4501' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4500/4500 25:18, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.576300</td>\n",
       "      <td>1.536637</td>\n",
       "      <td>0.303191</td>\n",
       "      <td>0.266273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.472500</td>\n",
       "      <td>1.478910</td>\n",
       "      <td>0.324468</td>\n",
       "      <td>0.198373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.562400</td>\n",
       "      <td>1.650946</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.153715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.594300</td>\n",
       "      <td>1.578707</td>\n",
       "      <td>0.228723</td>\n",
       "      <td>0.092748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.490200</td>\n",
       "      <td>1.452146</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.194253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.417800</td>\n",
       "      <td>1.443380</td>\n",
       "      <td>0.303191</td>\n",
       "      <td>0.157717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.413100</td>\n",
       "      <td>1.729651</td>\n",
       "      <td>0.207447</td>\n",
       "      <td>0.110654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.406400</td>\n",
       "      <td>1.425386</td>\n",
       "      <td>0.303191</td>\n",
       "      <td>0.164089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.633000</td>\n",
       "      <td>1.610565</td>\n",
       "      <td>0.223404</td>\n",
       "      <td>0.081591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.580900</td>\n",
       "      <td>1.528393</td>\n",
       "      <td>0.260638</td>\n",
       "      <td>0.139141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.501200</td>\n",
       "      <td>1.488712</td>\n",
       "      <td>0.271277</td>\n",
       "      <td>0.145390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.483400</td>\n",
       "      <td>1.413155</td>\n",
       "      <td>0.313830</td>\n",
       "      <td>0.266197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.408400</td>\n",
       "      <td>1.386716</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.228750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.330300</td>\n",
       "      <td>1.386573</td>\n",
       "      <td>0.329787</td>\n",
       "      <td>0.218298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.267600</td>\n",
       "      <td>1.317386</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.290291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.272200</td>\n",
       "      <td>1.331373</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.229813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.192500</td>\n",
       "      <td>1.241166</td>\n",
       "      <td>0.388298</td>\n",
       "      <td>0.338124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.194400</td>\n",
       "      <td>1.269826</td>\n",
       "      <td>0.409574</td>\n",
       "      <td>0.352311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.051100</td>\n",
       "      <td>1.234942</td>\n",
       "      <td>0.441489</td>\n",
       "      <td>0.389104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.005600</td>\n",
       "      <td>1.320194</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.370418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.149400</td>\n",
       "      <td>1.373671</td>\n",
       "      <td>0.441489</td>\n",
       "      <td>0.390565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.933900</td>\n",
       "      <td>1.276579</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.407088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.918600</td>\n",
       "      <td>1.387977</td>\n",
       "      <td>0.441489</td>\n",
       "      <td>0.387227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.866400</td>\n",
       "      <td>1.389299</td>\n",
       "      <td>0.478723</td>\n",
       "      <td>0.424814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.798500</td>\n",
       "      <td>1.458605</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>0.404256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>1.487520</td>\n",
       "      <td>0.473404</td>\n",
       "      <td>0.415219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.640300</td>\n",
       "      <td>1.499079</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.435966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>1.469064</td>\n",
       "      <td>0.505319</td>\n",
       "      <td>0.452597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.583700</td>\n",
       "      <td>1.521886</td>\n",
       "      <td>0.478723</td>\n",
       "      <td>0.430084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.561400</td>\n",
       "      <td>1.482999</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.458476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 7: Start Training\n",
    "try:\n",
    "    print(\"Starting training...\")\n",
    "    train_result = trainer.train()\n",
    "    print(\"\\nTraining completed!\")\n",
    "    print(f\"Final metrics: {train_result.metrics}\")\n",
    "    \n",
    "except RuntimeError as e:\n",
    "    if \"CUDA out of memory\" in str(e):\n",
    "        print(\"Memory error! Reduce batch size or model size\")\n",
    "    else:\n",
    "        print(\"Training failed:\")\n",
    "    raise\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Unexpected error during training:\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
